{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digital Activity Schema Standard Class Notebook\r\n",
        "\r\n",
        "This schema standardization class notebook outlines the 3 necessary functions for processing module schemas into the OEA digital activity schema standard.\r\n",
        "\r\n",
        "These 4 functions are:\r\n",
        "\r\n",
        " - get_digital_activity_schema - which defines what the digital activity standard consists of, and how to map other data sources to this OEA standard.\r\n",
        " - reset_digital_activity_processing - which deletes the \"digital_activity\" folder from stage 2p, allowing you to start over the schema standardization process. \r\n",
        " - initialize_standardization - which takes in the user-defined module and tables wanted for processing (at the pipeline-level), does any pre-processing needed for the data, and pushes those tables to \"_process_digital_activity\".\r\n",
        " - _process_digital_activity - which takes in the user-defined schema mapping and source folder, while executing the standardization process to be re-written back to stage 2p.\r\n",
        "\r\n",
        " Any custom/additional data source schema mappings should be defined here."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitalActivity(BaseOEAModule):\r\n",
        "    \"\"\"\r\n",
        "    Currently, package class notebook only contains processing for stage2p data.\r\n",
        "     - Reads activity data from stage2p, writes the activity data schema/relationship mapping to stage2p again\r\n",
        "     - Then takes this mapping and generalized and method for writing to stage3p\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, source_folder='digital_activity'):\r\n",
        "        BaseOEAModule.__init__(self, oea, source_folder)\r\n",
        "\r\n",
        "        self.schemas['ActivityEvents'] = [['event_id', 'string', 'no-op'],\r\n",
        "                        ['event_type', 'string', 'no-op'],\r\n",
        "                        ['event_actor', 'string', 'no-op'],\r\n",
        "                        ['event_object', 'string', 'no-op'],\r\n",
        "                        ['event_eventTime', 'string', 'no-op'],\r\n",
        "                        ['entity_type', 'string', 'no-op'], \r\n",
        "                        ['softwareApplication_version', 'string', 'no-op'], \r\n",
        "                        ['generated_aggregateMeasure_metric_timeOnTaskSec', 'string', 'no-op'], \r\n",
        "                        ['generated_aggregateMeasure_metric_numAccess', 'string', 'no-op'],\r\n",
        "                        ['generated_aggregateMeasure_metric_used', 'string', 'no-op'],\r\n",
        "                        ['generated_aggregateMeasure_metric_activityReportPeriod', 'string', 'no-op'], \r\n",
        "                        ['year', 'integer', 'no-op'], \r\n",
        "                        ['month', 'integer', 'no-op']]\r\n",
        "\r\n",
        "        self.schemasDetail = {}\r\n",
        "        self.schemasDetail['ActivityEvents'] = [['schema_source', 'https://www.imsglobal.org/spec/caliper/v1p2#tooluseevent'],\r\n",
        "                        ['event_id','unique ID used as a signal key'],\r\n",
        "                        ['event_type', 'type of activity event'],\r\n",
        "                        ['event_actor', 'student or teacher that created the signal'],\r\n",
        "                        ['event_object', 'entity that comprises the object of the interaction'],\r\n",
        "                        ['event_eventTime', 'date/timestamp of the activity signal'],\r\n",
        "                        ['entity_type', 'value that describes the properties of the user agent hosting this SoftwareApplication.'],\r\n",
        "                        ['softwareApplication_version', 'value that describes the properties of the user agent hosting this SoftwareApplication.'],\r\n",
        "                        ['generated_aggregateMeasure_metric_timeOnTaskSec', 'time on task in seconds'],\r\n",
        "                        ['generated_aggregateMeasure_metric_numAccess', 'number of accesses'], \r\n",
        "                        ['generated_aggregateMeasure_metric_used', 'used true or false'], \r\n",
        "                        ['generated_aggregateMeasure_metric_activityReportPeriod', 'activity data collected is reported over this number of days']]\r\n",
        "\r\n",
        "        # Schema mapping for Module_Table \r\n",
        "        self.schemaMappings = {}\r\n",
        "        self.schemaMappings['M365_TechActivity'] =  [['event_id', 'SignalId'],\r\n",
        "                                                ['event_type', 'SignalType'], \r\n",
        "                                                ['event_actor', 'ActorId_pseudonym'],\r\n",
        "                                                ['event_object', 'MS_Insights'],\r\n",
        "                                                ['event_eventTime', 'StartTime'],\r\n",
        "                                                ['entity_type', 'AppName'],\r\n",
        "                                                ['softwareApplication_version', 'SchemaVersion'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_timeOnTaskSec', 'MeetingDuration']]\r\n",
        "        self.schemaMappings['GraphAPI_M365'] = [['event_actor', 'userPrincipalName_pseudonym'],\r\n",
        "                                                ['event_object', 'MS_GraphAPI_M365'],\r\n",
        "                                                ['event_eventTime', 'reportRefreshDate'],\r\n",
        "                                                ['entity_type', 'm365_app_name'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_used', 'used'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_activityReportPeriod', 'reportPeriod']]\r\n",
        "        self.schemaMappings['GraphAPI_Teams'] = [['event_type', 'meetings_and_messages'],\r\n",
        "                                                ['event_actor', 'userPrincipalName_pseudonym'],\r\n",
        "                                                ['event_object', 'MS_GraphAPI_Teams'],\r\n",
        "                                                ['event_eventTime', 'reportRefreshDate'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_timeOnTaskSec', 'videoDuration'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_numAccess', 'counts'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_activityReportPeriod', 'reportPeriod']]\r\n",
        "        self.schemaMappings['Clever_DailyParticipation'] = [['event_actor', 'sis_id_pseudonym'],\r\n",
        "                                                ['event_object', 'Clever_Daily_Participation'],\r\n",
        "                                                ['event_eventTime', 'date'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_used', 'active'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_numAccess', 'num_logins']]\r\n",
        "        self.schemaMappings['Clever_ResourceUsage'] = [['event_type', 'resource_type'],\r\n",
        "                                                ['event_actor', 'sis_id_pseudonym'],\r\n",
        "                                                ['event_object', 'Clever_Resource_Usage'],\r\n",
        "                                                ['event_eventTime', 'date'],\r\n",
        "                                                ['entity_type', 'resource_name'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_numAccess', 'num_access']]\r\n",
        "        self.schemaMappings['iReady_Comp_ELA'] = [['event_type', 'Subject'],\r\n",
        "                                                ['event_actor', 'StudentID_pseudonym'],\r\n",
        "                                                ['event_object', 'iReady_Comprehensive_Student_Lesson_Activity_with_Standards_ELA'],\r\n",
        "                                                ['event_eventTime', 'CompletionDate'],\r\n",
        "                                                ['entity_type', 'Domain'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_timeOnTaskSec', 'TotalTimeonLesson_sec_']]\r\n",
        "        self.schemaMappings['iReady_Comp_Math'] = [['event_type', 'Subject'],\r\n",
        "                                                ['event_actor', 'StudentID_pseudonym'],\r\n",
        "                                                ['event_object', 'iReady_Comprehensive_Student_Lesson_Activity_with_Standards_Math'],\r\n",
        "                                                ['event_eventTime', 'CompletionDate'],\r\n",
        "                                                ['entity_type', 'Domain'],\r\n",
        "                                                ['generated_aggregateMeasure_metric_timeOnTaskSec', 'TotalTimeonLesson_sec_']]\r\n",
        "\r\n",
        "\r\n",
        "    def get_digital_activity_schema(self):\r\n",
        "        \"\"\" Get information on digital activity schema\r\n",
        "            - needed to align schemas to activity data source\r\n",
        "        \"\"\"\r\n",
        "        print(\"OEA Standard Digital Activity Schema:\\n\")\r\n",
        "        \r\n",
        "        print(\"Columns and data types:\\n\")\r\n",
        "        for var in self.schemas['ActivityEvents']:\r\n",
        "            print(var)\r\n",
        "        \r\n",
        "        print(\"\\nColumn descriptions:\\n\")\r\n",
        "        for var in self.schemasDetail['ActivityEvents']:\r\n",
        "            print(var)\r\n",
        "\r\n",
        "\r\n",
        "    def reset_digital_activity_processing(self):\r\n",
        "        \"\"\" Resets all data. This is intended for use during initial testing - use with caution.\r\n",
        "            - deletes the delta table at stage2/digital_activity\r\n",
        "        \"\"\"\r\n",
        "        oea.rm_if_exists(self.stage2p)\r\n",
        "        logger.info(f\"Deleted {self.stage2p}\")\r\n",
        "\r\n",
        "    def initialize_standardization(self, module, table):\r\n",
        "        \"\"\" Initializes digital activity schema standardization.\r\n",
        "            - takes in the module and table expected to be standardized\r\n",
        "            - checks to ensure that module and table has defined processing\r\n",
        "            - some modules/tables have data pre-processing for consistency\r\n",
        "        \"\"\"\r\n",
        "        import pandas as pd\r\n",
        "\r\n",
        "        logger.info(\"Initializing standardization for digital activity schemas\")\r\n",
        "\r\n",
        "        # module: insights, table: TechActivity\r\n",
        "        if (module == 'M365') & (table == 'TechActivity_pseudo'):\r\n",
        "            # NOTE: pre-processing step (takes the student IDs in the Activity table, assigned from the Insights Person table, and maps them to the AADUser student IDs)\r\n",
        "                # Then transforms the MeetingDuration column from a duration to the total time, in seconds.\r\n",
        "            dfInsights_activity = oea.load(module,table)\r\n",
        "            dfInsights_studentIDMapping = oea.load('M365', 'AadUserPersonMapping_pseudo')\r\n",
        "            dfInsights = dfInsights_activity.join(dfInsights_studentIDMapping, dfInsights_activity.ActorId_pseudonym == dfInsights_studentIDMapping.PersonId_pseudonym, how='inner')\r\n",
        "            dfInsights = dfInsights.drop(F.col('ActorId_pseudonym'))\r\n",
        "            dfInsights = dfInsights.withColumnRenamed('PersonId_pseudonym', 'ActorId_pseudonym')\r\n",
        "            dfInsights = dfInsights.select(dfInsights_activity.columns[:])\r\n",
        "            dfInsights = dfInsights.withColumn('MeetingDuration', \r\n",
        "            F.coalesce(F.regexp_extract('MeetingDuration', r'(\\d+):(\\d+):(\\d+)', 1).cast('int'), F.lit(0)) * 3600 + \r\n",
        "            F.coalesce(F.regexp_extract('MeetingDuration', r'(\\d+):(\\d+):(\\d+)', 2).cast('int'), F.lit(0)) * 60 + \r\n",
        "            F.coalesce(F.regexp_extract('MeetingDuration', r'(\\d+):(\\d+):(\\d+)', 3).cast('int'), F.lit(0))\r\n",
        "            )\r\n",
        "            dfInsights = dfInsights.select(dfInsights_activity.columns[:])\r\n",
        "            dfInsights.write.save(oea.path('stage2p', directory_path=\"temp\"), format='delta', mode='append', mergeSchema='true')\r\n",
        "\r\n",
        "            source_path = 'stage2p/temp'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['M365_TechActivity'])\r\n",
        "            oea.rm_if_exists(oea.path('stage2p', directory_path=\"temp\"))\r\n",
        "        # module: graph_api, table: m365_app_user_detail\r\n",
        "        elif (module == 'graph_api') & (table == 'm365_app_user_detail_pseudo'):\r\n",
        "            # NOTE: pre-processing step (melts the usage columns into two)\r\n",
        "            dfGraph_M365 = oea.load(module,table)\r\n",
        "            dfPand = dfGraph_M365.toPandas()\r\n",
        "            dfPandMelt = dfPand.melt(id_vars = ['userPrincipalName_pseudonym', 'reportRefreshDate', 'reportPeriod'],value_vars = ['excel','oneNote', 'outlook', 'powerPoint', 'teams', 'word'],var_name='m365_app_name',value_name='used')\r\n",
        "            dfGraph_M365 = spark.createDataFrame(dfPandMelt)\r\n",
        "            dfGraph_M365.write.save(oea.path('stage2p', directory_path=\"temp\"), format='delta', mode='append', mergeSchema='true')\r\n",
        "\r\n",
        "            source_path = 'stage2p/temp'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['GraphAPI_M365'])\r\n",
        "            oea.rm_if_exists(oea.path('stage2p', directory_path=\"temp\"))\r\n",
        "        # module: graph_api, table: teams_activity_user_detail\r\n",
        "        elif (module == 'graph_api') & (table == 'teams_activity_user_detail_pseudo'):\r\n",
        "            # NOTE: pre-processing step (melts the message and meeting count columns into two)\r\n",
        "            dfGraph_Teams = oea.load(module,table)\r\n",
        "            dfPand = dfGraph_Teams.toPandas()\r\n",
        "            dfPandMelt = dfPand.melt(id_vars = ['userPrincipalName_pseudonym', 'reportRefreshDate', 'reportPeriod', 'videoDuration'],value_vars = ['callCount', 'meetingCount', 'meetingsAttendedCount', 'meetingsOrganizedCount', 'privateChatMessageCount', 'teamChatMessageCount'],var_name='meetings_and_messages',value_name='counts')\r\n",
        "            dfGraph_Teams_counts = spark.createDataFrame(dfPandMelt)\r\n",
        "            dfGraph_Teams_counts.write.save(oea.path('stage2p', directory_path=\"temp\"), format='delta', mode='append', mergeSchema='true')\r\n",
        "\r\n",
        "            source_path = 'stage2p/temp'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['GraphAPI_Teams'])\r\n",
        "            oea.rm_if_exists(oea.path('stage2p', directory_path=\"temp\"))\r\n",
        "        # module: clever, table: daily_participation\r\n",
        "        elif (module == 'clever') & (table == 'daily_participation_pseudo'):\r\n",
        "            source_path = 'stage2p/clever/daily_participation_pseudo'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['Clever_DailyParticipation'])\r\n",
        "        # module: clever, table: resource_usage\r\n",
        "        elif (module == 'clever') & (table == 'resource_usage_pseudo'):\r\n",
        "            source_path = 'stage2p/clever/resource_usage_pseudo'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['Clever_ResourceUsage'])\r\n",
        "        # module: iready, table: comprehensive_..._ela\r\n",
        "        elif (module == 'iready') & (table == 'comprehensive_student_lesson_activity_with_standards_ela_pseudo'):\r\n",
        "            # NOTE: pre-processing step (convert original time in min to standard in sec)\r\n",
        "            dfiReady_Comp_ELA = oea.load(module,table)\r\n",
        "            dfiReady_Comp_ELA = dfiReady_Comp_ELA.withColumn('TotalTimeonLesson_min_', F.col('TotalTimeonLesson_min_')*60)\r\n",
        "            dfiReady_Comp_ELA = dfiReady_Comp_ELA.withColumnRenamed('TotalTimeonLesson_min_', 'TotalTimeonLesson_sec_')\r\n",
        "            dfiReady_Comp_ELA.write.save(oea.path('stage2p', directory_path=\"temp\"), format='delta', mode='append', mergeSchema='true')\r\n",
        "\r\n",
        "            source_path = 'stage2p/temp'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['iReady_Comp_ELA'])\r\n",
        "            oea.rm_if_exists(oea.path('stage2p', directory_path=\"temp\"))\r\n",
        "        # module: iready, table: comprehensive_..._math\r\n",
        "        elif (module == 'iready') & (table == 'comprehensive_student_lesson_activity_with_standards_math_pseudo'):\r\n",
        "            # NOTE: pre-processing step (convert original time in min to standard in sec)\r\n",
        "            dfiReady_Comp_Math = oea.load(module,table)\r\n",
        "            dfiReady_Comp_Math = dfiReady_Comp_Math.withColumn('TotalTimeonLesson_min_', F.col('TotalTimeonLesson_min_')*60)\r\n",
        "            dfiReady_Comp_Math = dfiReady_Comp_Math.withColumnRenamed('TotalTimeonLesson_min_', 'TotalTimeonLesson_sec_')\r\n",
        "            dfiReady_Comp_Math.write.save(oea.path('stage2p', directory_path=\"temp\"), format='delta', mode='append', mergeSchema='true')\r\n",
        "\r\n",
        "            source_path = 'stage2p/temp'\r\n",
        "            self._process_digital_activity(source_path, self.schemaMappings['iReady_Comp_Math'])\r\n",
        "            oea.rm_if_exists(oea.path('stage2p', directory_path=\"temp\"))\r\n",
        "        else: \r\n",
        "            logger.info(\"No defined process for the module or table initialized\")\r\n",
        "    \r\n",
        "    def _process_digital_activity(self,source_path,schemaMapping):\r\n",
        "        \"\"\" Processes digital activity data into standardized table with standard activity schema.\r\n",
        "            - source_path: Storage location and directory name of table after pre-processing (e.g. stage2p/temp) - used for appending to the digital_activity table\r\n",
        "            - checkpoint_path: Storage location and directory name of table before pre-processing (e.g. stage2p/graph_api/m365_app_user_detail_pseudo) - used for checkpoint location for digital_activity table\r\n",
        "            - schemaMapping: mapping of table columns to ActivityEvents schema, NULL if no mapping provided\r\n",
        "        \"\"\"\r\n",
        "        from pyspark.sql.functions import lit\r\n",
        "\r\n",
        "        logger.info(\"Processing digital activity data from: \" + source_path)\r\n",
        "        \r\n",
        "        dfActivity = oea.load_delta(source_path)\r\n",
        "\r\n",
        "        df = spark.createDataFrame(schemaMapping, schema = [\"schema\", \"source\"])\r\n",
        "        df = df.na.drop(\"any\")\r\n",
        "\r\n",
        "        obj = df.filter(df['schema'] == \"event_object\").collect()[0][1]\r\n",
        "        dfCols = df.filter(df['schema'] != \"event_object\")\r\n",
        "\r\n",
        "        colList = dfCols.select('source').collect()\r\n",
        "        colList = [col.source for col in colList]\r\n",
        "\r\n",
        "        df = dfActivity.select(colList)\r\n",
        "\r\n",
        "        # rename source column to be schema column\r\n",
        "        for row in dfCols.rdd.collect():\r\n",
        "            schemaCol = row[0]\r\n",
        "            sourceCol = row[1]\r\n",
        "            df = df.withColumnRenamed(sourceCol, schemaCol)\r\n",
        "            df = df.withColumn(schemaCol, df[schemaCol].cast(StringType()))\r\n",
        "                    \r\n",
        "        df = df.withColumn('event_object', F.lit(obj))\r\n",
        "        df = df.withColumn('year', F.year(F.col('event_eventTime'))).withColumn('month', F.month(F.col('event_eventTime')))\r\n",
        "        df.write.save(oea.path('stage2p', directory_path=\"digital_activity\"), format='delta', mode='append', partitionBy=['year', 'month'], mergeSchema='true')\r\n",
        "        \r\n",
        "        logger.info(\"Complete processing from: \" + source_path)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}